import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader
import numpy as np
import time
import pandas as pd
from typing import Dict, List, Tuple
import warnings
warnings.filterwarnings('ignore')

# å¯¼å…¥æ¨¡å‹å’Œè¯„ä¼°æ¡†æ¶
from model_a_gnn import ModelA_GNN, ModelALoss
from model_b_similarity import ModelB_Similarity, ModelBLoss
from data_generation import SyntheticDataGenerator
from evaluation_framework import GraphPostProcessor, SpectralClusteringEvaluator, ModularityCalculator


class LightweightMoonsTest:
    def __init__(self, device='cpu'):
        self.device = device
        
        # æç®€æ¨¡å‹é…ç½®
        self.model_config_a = {
            'input_channels': 1,
            'feature_dim': 32,    # å¤§å¹…å‡å°‘
            'max_nodes': 50,      # å¤§å¹…å‡å°‘
            'coord_dim': 2,
            'hidden_dim': 8,      # å¤§å¹…å‡å°‘
            'node_feature_dim': 8 # å¤§å¹…å‡å°‘
        }
        
        self.model_config_b = {
            'input_channels': 1,
            'feature_dim': 32,    # å¤§å¹…å‡å°‘
            'max_nodes': 50,      # å¤§å¹…å‡å°‘
            'coord_dim': 2,
            'similarity_hidden_dim': 4  # å¤§å¹…å‡å°‘
        }
        
        # æç®€è®­ç»ƒé…ç½®
        self.training_config = {
            'batch_size': 4,      # å°æ‰¹æ¬¡
            'learning_rate': 0.01, # é«˜å­¦ä¹ ç‡å¿«é€Ÿæ”¶æ•›
            'epochs': 5,          # æå°‘è½®æ•°
            'weight_decay': 1e-4
        }
        
        # åˆå§‹åŒ–æ¨¡å‹
        self.model_a = ModelA_GNN(**self.model_config_a).to(self.device)
        self.model_b = ModelB_Similarity(**self.model_config_b).to(self.device)
        
        # æŸå¤±å‡½æ•°
        self.loss_a = ModelALoss(coord_weight=1.0, edge_weight=1.0, count_weight=0.1)
        self.loss_b = ModelBLoss(coord_weight=1.0, edge_weight=1.0, count_weight=0.1, similarity_weight=0.5)
        
        # ä¼˜åŒ–å™¨
        self.optimizer_a = optim.Adam(self.model_a.parameters(), 
                                    lr=self.training_config['learning_rate'], 
                                    weight_decay=self.training_config['weight_decay'])
        self.optimizer_b = optim.Adam(self.model_b.parameters(), 
                                    lr=self.training_config['learning_rate'], 
                                    weight_decay=self.training_config['weight_decay'])
        
        # è¯„ä¼°ç»„ä»¶
        self.graph_processor = GraphPostProcessor(k_top_edges=5)  # å‡å°‘è¾¹æ•°
        self.spectral_evaluator = SpectralClusteringEvaluator(n_clusters=2, random_state=42)
        self.modularity_calculator = ModularityCalculator()
        
        # ç»“æœå­˜å‚¨
        self.results = {
            'model_a': {'metrics': [], 'inference_times': []},
            'model_b': {'metrics': [], 'inference_times': []}
        }
    
    def generate_small_dataset(self, n_samples: int, dataset_type: str) -> List[Dict]:
        """ç”Ÿæˆå°è§„æ¨¡æ•°æ®é›†"""
        dataset = []
        
        for i in range(n_samples):
            n_points = np.random.randint(30, 51)  # å¾ˆå°‘çš„èŠ‚ç‚¹
            noise_level = np.random.uniform(0.05, 0.15)
            
            temp_generator = SyntheticDataGenerator(
                img_size=64, 
                n_samples=n_points, 
                noise=noise_level
            )
            data = temp_generator.generate_dataset(dataset_type, n_points)
            dataset.append(data)
        
        return dataset
    
    def prepare_batch(self, batch_data: List[Dict]) -> Tuple[torch.Tensor, Dict[str, torch.Tensor]]:
        """å‡†å¤‡æ‰¹æ¬¡æ•°æ®"""
        batch_size = len(batch_data)
        max_nodes = self.model_config_a['max_nodes']
        
        # å‡†å¤‡å›¾åƒæ•°æ®
        images = torch.stack([torch.from_numpy(data['image']).unsqueeze(0) for data in batch_data])
        
        # å‡†å¤‡ç›®æ ‡æ•°æ®
        targets = {
            'points': torch.zeros(batch_size, max_nodes, 2),
            'node_masks': torch.zeros(batch_size, max_nodes, dtype=torch.bool),
            'adjacency': torch.zeros(batch_size, max_nodes, max_nodes),
            'labels': []
        }
        
        for i, data in enumerate(batch_data):
            n_points = len(data['points'])
            n_valid = min(n_points, max_nodes)
            
            # å¡«å……åæ ‡
            targets['points'][i, :n_valid] = torch.from_numpy(data['points'][:n_valid])
            
            # å¡«å……èŠ‚ç‚¹æ©ç 
            targets['node_masks'][i, :n_valid] = True
            
            # å¡«å……é‚»æ¥çŸ©é˜µ
            adj = torch.from_numpy(data['adjacency'][:n_valid, :n_valid])
            targets['adjacency'][i, :n_valid, :n_valid] = adj
            
            # å­˜å‚¨çœŸå®æ ‡ç­¾
            targets['labels'].append(data['labels'][:n_valid])
        
        return images, targets
    
    def quick_train(self, model: nn.Module, optimizer: optim.Optimizer, loss_fn: nn.Module, 
                   train_loader: DataLoader, model_name: str) -> List[float]:
        """å¿«é€Ÿè®­ç»ƒ"""
        model.train()
        train_losses = []
        
        print(f"å¼€å§‹å¿«é€Ÿè®­ç»ƒ{model_name}...")
        
        for epoch in range(self.training_config['epochs']):
            epoch_loss = 0.0
            num_batches = 0
            
            for batch_data in train_loader:
                images, targets = self.prepare_batch(batch_data)
                images = images.to(self.device)
                targets = {k: v.to(self.device) if isinstance(v, torch.Tensor) else v for k, v in targets.items()}
                
                optimizer.zero_grad()
                
                predictions = model(images, targets['node_masks'])
                loss_dict = loss_fn(predictions, targets)
                total_loss = sum(loss_dict.values())
                
                total_loss.backward()
                optimizer.step()
                
                epoch_loss += total_loss.item()
                num_batches += 1
            
            avg_loss = epoch_loss / num_batches
            train_losses.append(avg_loss)
            
            print(f"  Epoch {epoch+1}/{self.training_config['epochs']} - Loss: {avg_loss:.4f}")
        
        print(f"âœ… {model_name} è®­ç»ƒå®Œæˆ")
        return train_losses
    
    def quick_evaluate(self, model: nn.Module, test_data: List[Dict], model_name: str):
        """å¿«é€Ÿè¯„ä¼°"""
        print(f"\nå¿«é€Ÿè¯„ä¼°{model_name}...")
        
        all_metrics = []
        all_inference_times = []
        
        for i, data in enumerate(test_data):
            print(f"  è¯„ä¼°æ ·æœ¬ {i+1}/{len(test_data)}")
            
            # å‡†å¤‡æ•°æ®
            image = torch.from_numpy(data['image']).unsqueeze(0).to(self.device)
            n_points = len(data['points'])
            n_valid = min(n_points, self.model_config_a['max_nodes'])
            
            node_mask = torch.zeros(self.model_config_a['max_nodes'], dtype=torch.bool)
            node_mask[:n_valid] = True
            node_mask = node_mask.to(self.device)
            
            true_labels = data['labels'][:n_valid]
            
            # è¯„ä¼°
            model.eval()
            with torch.no_grad():
                start_time = time.time()
                predictions = model(image, node_mask)
                end_time = time.time()
                inference_time = (end_time - start_time) * 1000
                
                # è·å–é‚»æ¥çŸ©é˜µ
                adjacency = predictions['adjacency_matrix'][0].cpu().numpy()
                
                # å¤„ç†é‚»æ¥çŸ©é˜µ
                processed_adjacency = self.graph_processor.process(adjacency)
                
                # è°±èšç±»
                predicted_labels = self.spectral_evaluator.cluster(processed_adjacency)
                
                # ç¡®ä¿æ ‡ç­¾é•¿åº¦åŒ¹é…
                n_valid = min(len(predicted_labels), len(true_labels))
                predicted_labels = predicted_labels[:n_valid]
                true_labels = true_labels[:n_valid]
                
                # è®¡ç®—æŒ‡æ ‡
                clustering_metrics = self.spectral_evaluator.evaluate_clustering(predicted_labels, true_labels)
                modularity = self.modularity_calculator.calculate_modularity(processed_adjacency, predicted_labels)
                
                metrics = {
                    'ari': clustering_metrics['ari'],
                    'nmi': clustering_metrics['nmi'],
                    'modularity': modularity,
                    'inference_time_ms': inference_time
                }
                
                all_metrics.append(metrics)
                all_inference_times.append(inference_time)
                
                print(f"    ARI: {metrics['ari']:.3f}, NMI: {metrics['nmi']:.3f}, æ—¶é—´: {inference_time:.1f}ms")
        
        # è®¡ç®—å¹³å‡æŒ‡æ ‡
        avg_metrics = {
            'ari': np.mean([m['ari'] for m in all_metrics]),
            'nmi': np.mean([m['nmi'] for m in all_metrics]),
            'modularity': np.mean([m['modularity'] for m in all_metrics]),
            'inference_time_ms': np.mean(all_inference_times)
        }
        
        self.results[model_name]['metrics'] = all_metrics
        self.results[model_name]['inference_times'] = all_inference_times
        
        print(f"âœ… {model_name} è¯„ä¼°å®Œæˆ")
        print(f"  å¹³å‡ARI: {avg_metrics['ari']:.3f}")
        print(f"  å¹³å‡NMI: {avg_metrics['nmi']:.3f}")
        print(f"  å¹³å‡Modularity: {avg_metrics['modularity']:.3f}")
        print(f"  å¹³å‡æ¨ç†æ—¶é—´: {avg_metrics['inference_time_ms']:.1f}ms")
        
        return avg_metrics
    
    def run_lightweight_test(self):
        """è¿è¡Œè½»é‡çº§æµ‹è¯•"""
        print("="*50)
        print("è½»é‡çº§åŒæœˆæ•°æ®é›†æ³›åŒ–èƒ½åŠ›éªŒè¯")
        print("="*50)
        print(f"ä½¿ç”¨è®¾å¤‡: {self.device}")
        print(f"æ¨¡å‹Aå‚æ•°æ•°é‡: {self.model_a.count_parameters():,}")
        print(f"æ¨¡å‹Bå‚æ•°æ•°é‡: {self.model_b.count_parameters():,}")
        
        # ç”Ÿæˆå°è§„æ¨¡è®­ç»ƒæ•°æ®ï¼ˆåœ†å½¢æ•°æ®ï¼‰
        print("\nğŸ“Š ç”Ÿæˆå°è§„æ¨¡è®­ç»ƒæ•°æ®ï¼ˆåœ†å½¢æ•°æ®é›†ï¼‰...")
        train_data = self.generate_small_dataset(10, 'circles')  # åªæœ‰10ä¸ªæ ·æœ¬
        print("âœ… è®­ç»ƒæ•°æ®ç”Ÿæˆå®Œæˆ")
        
        # ç”Ÿæˆå°è§„æ¨¡æµ‹è¯•æ•°æ®ï¼ˆåŒæœˆæ•°æ®ï¼‰
        print("\nğŸ“Š ç”Ÿæˆå°è§„æ¨¡æµ‹è¯•æ•°æ®ï¼ˆåŒæœˆæ•°æ®é›†ï¼‰...")
        test_data = self.generate_small_dataset(8, 'moons')  # åªæœ‰8ä¸ªæ ·æœ¬
        print("âœ… æµ‹è¯•æ•°æ®ç”Ÿæˆå®Œæˆ")
        
        # åˆ›å»ºæ•°æ®åŠ è½½å™¨
        train_loader = DataLoader(train_data, batch_size=self.training_config['batch_size'], 
                                shuffle=True, collate_fn=lambda x: x)
        
        print(f"\nğŸš€ å¼€å§‹å¿«é€Ÿè®­ç»ƒ...")
        print(f"è®­ç»ƒé…ç½®: {self.training_config['epochs']} epochs, batch_size={self.training_config['batch_size']}")
        
        # è®­ç»ƒæ¨¡å‹A
        print("\n" + "="*30)
        print("ğŸ”§ è®­ç»ƒæ¨¡å‹A")
        print("="*30)
        start_time = time.time()
        train_losses_a = self.quick_train(self.model_a, self.optimizer_a, self.loss_a, train_loader, "Model A")
        train_time_a = time.time() - start_time
        print(f"è®­ç»ƒè€—æ—¶: {train_time_a:.2f}ç§’")
        
        # è®­ç»ƒæ¨¡å‹B
        print("\n" + "="*30)
        print("ğŸ”§ è®­ç»ƒæ¨¡å‹B")
        print("="*30)
        start_time = time.time()
        train_losses_b = self.quick_train(self.model_b, self.optimizer_b, self.loss_b, train_loader, "Model B")
        train_time_b = time.time() - start_time
        print(f"è®­ç»ƒè€—æ—¶: {train_time_b:.2f}ç§’")
        
        print(f"\nğŸ“ˆ å¼€å§‹å¿«é€Ÿè¯„ä¼°...")
        
        # è¯„ä¼°æ¨¡å‹A
        metrics_a = self.quick_evaluate(self.model_a, test_data, 'model_a')
        
        # è¯„ä¼°æ¨¡å‹B
        metrics_b = self.quick_evaluate(self.model_b, test_data, 'model_b')
        
        # åˆ†æç»“æœ
        self.analyze_results()
        
        # ä¿å­˜ç»“æœ
        self.save_results()
    
    def analyze_results(self):
        """åˆ†æç»“æœ"""
        print("\n" + "="*50)
        print("è½»é‡çº§æ³›åŒ–èƒ½åŠ›åˆ†æç»“æœ")
        print("="*50)
        
        # è®¡ç®—ç»Ÿè®¡ä¿¡æ¯
        for model_name in ['model_a', 'model_b']:
            metrics = self.results[model_name]['metrics']
            
            ari_values = [m['ari'] for m in metrics]
            nmi_values = [m['nmi'] for m in metrics]
            modularity_values = [m['modularity'] for m in metrics]
            inference_times = [m['inference_time_ms'] for m in metrics]
            
            print(f"\n{model_name.upper()} ç»Ÿè®¡ä¿¡æ¯:")
            print(f"  ARI: {np.mean(ari_values):.3f} Â± {np.std(ari_values):.3f}")
            print(f"  NMI: {np.mean(nmi_values):.3f} Â± {np.std(nmi_values):.3f}")
            print(f"  Modularity: {np.mean(modularity_values):.3f} Â± {np.std(modularity_values):.3f}")
            print(f"  æ¨ç†æ—¶é—´: {np.mean(inference_times):.1f} Â± {np.std(inference_times):.1f} ms")
        
        # æ¯”è¾ƒä¸¤ä¸ªæ¨¡å‹
        print("\næ¨¡å‹æ¯”è¾ƒ:")
        model_a_ari = np.mean([m['ari'] for m in self.results['model_a']['metrics']])
        model_b_ari = np.mean([m['ari'] for m in self.results['model_b']['metrics']])
        
        if model_a_ari > model_b_ari:
            print(f"âœ… æ¨¡å‹Aåœ¨ARIä¸Šè¡¨ç°æ›´å¥½: {model_a_ari:.3f} vs {model_b_ari:.3f}")
        else:
            print(f"âœ… æ¨¡å‹Båœ¨ARIä¸Šè¡¨ç°æ›´å¥½: {model_b_ari:.3f} vs {model_a_ari:.3f}")
        
        # æ³›åŒ–èƒ½åŠ›è¯„ä¼°
        print("\næ³›åŒ–èƒ½åŠ›è¯„ä¼°:")
        if model_a_ari > 0.3:
            print(f"âœ… æ¨¡å‹Aåœ¨åŒæœˆæ•°æ®é›†ä¸Šæ˜¾ç¤ºå‡ºæ³›åŒ–èƒ½åŠ› (ARI > 0.3)")
        else:
            print(f"âŒ æ¨¡å‹Aåœ¨åŒæœˆæ•°æ®é›†ä¸Šæ³›åŒ–èƒ½åŠ›æœ‰é™ (ARI â‰¤ 0.3)")
        
        if model_b_ari > 0.3:
            print(f"âœ… æ¨¡å‹Båœ¨åŒæœˆæ•°æ®é›†ä¸Šæ˜¾ç¤ºå‡ºæ³›åŒ–èƒ½åŠ› (ARI > 0.3)")
        else:
            print(f"âŒ æ¨¡å‹Båœ¨åŒæœˆæ•°æ®é›†ä¸Šæ³›åŒ–èƒ½åŠ›æœ‰é™ (ARI â‰¤ 0.3)")
    
    def save_results(self):
        """ä¿å­˜ç»“æœ"""
        # åˆ›å»ºç»“æœDataFrame
        results_data = []
        
        for model_name in ['model_a', 'model_b']:
            metrics = self.results[model_name]['metrics']
            
            avg_ari = np.mean([m['ari'] for m in metrics])
            avg_nmi = np.mean([m['nmi'] for m in metrics])
            avg_modularity = np.mean([m['modularity'] for m in metrics])
            avg_inference_time = np.mean([m['inference_time_ms'] for m in metrics])
            
            # åˆ¤æ–­æ˜¯å¦è¾¾åˆ°ç›®æ ‡
            meets_ari_target = avg_ari > 0.3  # é™ä½ç›®æ ‡
            beats_sklearn = avg_inference_time < 50  # é™ä½ç›®æ ‡
            
            results_data.append({
                'Method': model_name.replace('_', ' ').title(),
                'ARI': avg_ari,
                'NMI': avg_nmi,
                'Modularity': avg_modularity,
                'Inference_Time_ms': avg_inference_time,
                'Meets_ARI_Target': meets_ari_target,
                'Beats_Sklearn': beats_sklearn,
                'Description': f'Lightweight {model_name.replace("_", " ").title()} on moons dataset'
            })
        
        # ä¿å­˜åˆ°CSV
        df = pd.DataFrame(results_data)
        df.to_csv('lightweight_moons_results.csv', index=False)
        
        print(f"\nç»“æœå·²ä¿å­˜åˆ° lightweight_moons_results.csv")
        print(df.to_string(index=False))


def main():
    """ä¸»å‡½æ•°"""
    evaluator = LightweightMoonsTest()
    evaluator.run_lightweight_test()


if __name__ == "__main__":
    main() 