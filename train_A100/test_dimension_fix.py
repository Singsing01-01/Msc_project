#!/usr/bin/env python3
"""
æµ‹è¯•ç»´åº¦ä¿®å¤åçš„æ¨¡å‹
"""

import torch
from models.model_a_gnn_a100 import ModelA_GNN_A100, ModelA_A100_Loss

def test_model_dimensions():
    """æµ‹è¯•æ¨¡å‹ç»´åº¦æ˜¯å¦æ­£ç¡®"""
    print("ğŸ”§ æµ‹è¯•æ¨¡å‹ç»´åº¦ä¿®å¤...")
    
    # è®¾ç½®è®¾å¤‡
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    print(f"ä½¿ç”¨è®¾å¤‡: {device}")
    
    # åˆ›å»ºæ¨¡å‹
    model = ModelA_GNN_A100(
        input_channels=1,
        feature_dim=256,
        max_nodes=350,
        coord_dim=2,
        hidden_dim=128,
        node_feature_dim=64
    ).to(device)
    
    print(f"æ¨¡å‹å‚æ•°æ•°é‡: {model.count_parameters():,}")
    
    # åˆ›å»ºæµ‹è¯•æ•°æ®
    batch_size = 2
    max_nodes = 350
    
    images = torch.randn(batch_size, 1, 64, 64).to(device)
    node_masks = torch.ones(batch_size, max_nodes, dtype=torch.bool).to(device)
    # è®¾ç½®å®é™…èŠ‚ç‚¹æ•°
    node_masks[0, 10:] = False  # ç¬¬ä¸€ä¸ªæ ·æœ¬10ä¸ªèŠ‚ç‚¹
    node_masks[1, 15:] = False  # ç¬¬äºŒä¸ªæ ·æœ¬15ä¸ªèŠ‚ç‚¹
    
    print(f"è¾“å…¥å½¢çŠ¶:")
    print(f"  images: {images.shape}")
    print(f"  node_masks: {node_masks.shape}")
    print(f"  æœ‰æ•ˆèŠ‚ç‚¹æ•°: {node_masks.sum(dim=1)}")
    
    # æµ‹è¯•å‰å‘ä¼ æ’­
    try:
        print("\nğŸ”„ æµ‹è¯•å‰å‘ä¼ æ’­...")
        model.eval()
        with torch.no_grad():
            predictions = model(images, node_masks)
        
        print("âœ… å‰å‘ä¼ æ’­æˆåŠŸ!")
        print(f"è¾“å‡ºå½¢çŠ¶:")
        for key, value in predictions.items():
            if isinstance(value, torch.Tensor):
                print(f"  {key}: {value.shape}")
            else:
                print(f"  {key}: {type(value)}")
        
        # æ£€æŸ¥å…³é”®è¾“å‡º
        pred_coords = predictions['predicted_coords']
        adj_matrix = predictions['adjacency_matrix']
        adj_logits = predictions['adjacency_logits']
        node_features = predictions['node_features']
        
        print(f"\nğŸ“Š è¯¦ç»†æ£€æŸ¥:")
        print(f"  é¢„æµ‹åæ ‡èŒƒå›´: [{pred_coords.min():.4f}, {pred_coords.max():.4f}]")
        print(f"  é‚»æ¥çŸ©é˜µèŒƒå›´: [{adj_matrix.min():.4f}, {adj_matrix.max():.4f}]")
        print(f"  é‚»æ¥logitsèŒƒå›´: [{adj_logits.min():.4f}, {adj_logits.max():.4f}]")
        print(f"  èŠ‚ç‚¹ç‰¹å¾èŒƒå›´: [{node_features.min():.4f}, {node_features.max():.4f}]")
        
        # æ£€æŸ¥æ˜¯å¦æœ‰NaNæˆ–Inf
        def check_tensor_health(tensor, name):
            if torch.isnan(tensor).any():
                print(f"  âŒ {name} åŒ…å« NaN")
                return False
            if torch.isinf(tensor).any():
                print(f"  âŒ {name} åŒ…å« Inf")
                return False
            print(f"  âœ… {name} å¥åº·")
            return True
        
        print(f"\nğŸ¥ å¥åº·æ£€æŸ¥:")
        all_healthy = True
        all_healthy &= check_tensor_health(pred_coords, "é¢„æµ‹åæ ‡")
        all_healthy &= check_tensor_health(adj_matrix, "é‚»æ¥çŸ©é˜µ")
        all_healthy &= check_tensor_health(adj_logits, "é‚»æ¥logits")
        all_healthy &= check_tensor_health(node_features, "èŠ‚ç‚¹ç‰¹å¾")
        
        if all_healthy:
            print("ğŸ‰ æ‰€æœ‰è¾“å‡ºéƒ½å¥åº·!")
        
        return True
        
    except Exception as e:
        print(f"âŒ å‰å‘ä¼ æ’­å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False

def test_loss_computation():
    """æµ‹è¯•æŸå¤±è®¡ç®—"""
    print("\nğŸ”§ æµ‹è¯•æŸå¤±è®¡ç®—...")
    
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    
    # åˆ›å»ºæ¨¡å‹å’ŒæŸå¤±å‡½æ•°
    model = ModelA_GNN_A100(
        input_channels=1,
        feature_dim=256,
        max_nodes=350,
        coord_dim=2,
        hidden_dim=128,
        node_feature_dim=64
    ).to(device)
    
    criterion = ModelA_A100_Loss(
        coord_weight=1.0,
        edge_weight=1.0,
        count_weight=0.1,
        regularization_weight=0.001
    ).to(device)
    
    # åˆ›å»ºæµ‹è¯•æ•°æ®
    batch_size = 2
    max_nodes = 350
    
    images = torch.randn(batch_size, 1, 64, 64).to(device)
    points = torch.randn(batch_size, max_nodes, 2).to(device)
    adjacency = torch.rand(batch_size, max_nodes, max_nodes).to(device)
    node_masks = torch.ones(batch_size, max_nodes, dtype=torch.bool).to(device)
    node_masks[0, 10:] = False
    node_masks[1, 15:] = False
    
    try:
        model.train()
        predictions = model(images, node_masks)
        
        targets = {
            'points': points,
            'adjacency': adjacency,
            'node_masks': node_masks
        }
        
        loss_dict = criterion(predictions, targets)
        
        print("âœ… æŸå¤±è®¡ç®—æˆåŠŸ!")
        print("ğŸ“Š æŸå¤±è¯¦æƒ…:")
        for key, value in loss_dict.items():
            if torch.isnan(value):
                print(f"  âŒ {key}: NaN")
            elif torch.isinf(value):
                print(f"  âŒ {key}: Inf")
            else:
                print(f"  âœ… {key}: {value.item():.6f}")
        
        return True
        
    except Exception as e:
        print(f"âŒ æŸå¤±è®¡ç®—å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False

if __name__ == "__main__":
    print("ğŸ§ª å¼€å§‹æ¨¡å‹ç»´åº¦æµ‹è¯•...")
    
    success1 = test_model_dimensions()
    success2 = test_loss_computation()
    
    if success1 and success2:
        print("\nğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡! æ¨¡å‹æ¶æ„æ­£ç¡®!")
        print("âœ… ç°åœ¨å¯ä»¥å®‰å…¨è¿è¡Œå®Œæ•´è®­ç»ƒ:")
        print("   python training_pipeline_a100.py")
    else:
        print("\nâŒ æµ‹è¯•å¤±è´¥ï¼Œéœ€è¦è¿›ä¸€æ­¥è°ƒè¯•")