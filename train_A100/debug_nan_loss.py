#!/usr/bin/env python3
"""
è°ƒè¯•NaNæŸå¤±é—®é¢˜
"""

import torch
import torch.nn as nn
import numpy as np
from models.model_a_gnn_a100 import ModelA_GNN_A100, ModelA_A100_Loss
from data.data_generation_a100 import A100DataGenerator

def check_model_gradients(model):
    """æ£€æŸ¥æ¨¡å‹æ¢¯åº¦æ˜¯å¦åŒ…å«NaNæˆ–inf"""
    has_nan = False
    has_inf = False
    for name, param in model.named_parameters():
        if param.grad is not None:
            if torch.isnan(param.grad).any():
                print(f"âŒ NaN gradient in {name}")
                has_nan = True
            if torch.isinf(param.grad).any():
                print(f"âŒ Inf gradient in {name}")
                has_inf = True
    return has_nan, has_inf

def check_tensor_health(tensor, name):
    """æ£€æŸ¥å¼ é‡å¥åº·çŠ¶å†µ"""
    if torch.isnan(tensor).any():
        print(f"âŒ {name} contains NaN")
        return False
    if torch.isinf(tensor).any():
        print(f"âŒ {name} contains Inf")
        return False
    if (tensor == 0).all():
        print(f"âš ï¸  {name} is all zeros")
    print(f"âœ… {name} is healthy - range: [{tensor.min():.6f}, {tensor.max():.6f}]")
    return True

def debug_model_step():
    """é€æ­¥è°ƒè¯•æ¨¡å‹å‰å‘ä¼ æ’­"""
    print("ğŸ” å¼€å§‹è°ƒè¯•NaNæŸå¤±é—®é¢˜...")
    
    # è®¾ç½®è®¾å¤‡
    device = torch.device('cpu')  # ä½¿ç”¨CPUè°ƒè¯•
    print(f"ä½¿ç”¨è®¾å¤‡: {device}")
    
    # åˆ›å»ºæ¨¡å‹
    model = ModelA_GNN_A100(
        input_channels=1,
        feature_dim=256,
        max_nodes=350,
        coord_dim=2,
        hidden_dim=128,
        node_feature_dim=64
    ).to(device)
    
    # åˆ›å»ºæŸå¤±å‡½æ•°
    criterion = ModelA_A100_Loss(
        coord_weight=1.0,
        edge_weight=2.5,
        count_weight=0.1,
        regularization_weight=0.01
    ).to(device)
    
    print(f"æ¨¡å‹å‚æ•°æ•°é‡: {model.count_parameters():,}")
    
    # åˆ›å»ºç®€å•çš„æµ‹è¯•æ•°æ®
    batch_size = 2
    max_nodes = 350
    
    # ç”ŸæˆçœŸå®æ•°æ®
    generator = A100DataGenerator()
    train_data, _ = generator.create_train_test_split_parallel(train_size=batch_size, test_size=1)
    
    print("\nğŸ“Š å‡†å¤‡æµ‹è¯•æ•°æ®...")
    images_list = []
    points_list = []
    adjacency_list = []
    masks_list = []
    
    for i in range(batch_size):
        sample = train_data[i]
        
        # å‡†å¤‡å›¾åƒ
        image = torch.from_numpy(sample['image']).unsqueeze(0).float()
        images_list.append(image)
        
        # å‡†å¤‡ç‚¹åæ ‡å’Œé‚»æ¥çŸ©é˜µ
        points = sample['points']
        adjacency = sample['adjacency']
        n_points = len(points)
        
        # å¡«å……åˆ°max_nodes
        points_padded = np.zeros((max_nodes, 2))
        points_padded[:n_points] = points
        
        adjacency_padded = np.zeros((max_nodes, max_nodes))
        adjacency_padded[:n_points, :n_points] = adjacency
        
        # åˆ›å»ºæ©ç 
        mask = torch.zeros(max_nodes, dtype=torch.bool)
        mask[:n_points] = True
        
        points_list.append(torch.from_numpy(points_padded).float())
        adjacency_list.append(torch.from_numpy(adjacency_padded).float())
        masks_list.append(mask)
    
    # å †å æˆæ‰¹æ¬¡
    images = torch.stack(images_list).to(device)
    points = torch.stack(points_list).to(device)
    adjacency = torch.stack(adjacency_list).to(device)
    node_masks = torch.stack(masks_list).to(device)
    
    # æ£€æŸ¥è¾“å…¥æ•°æ®å¥åº·çŠ¶å†µ
    print("\nğŸ” æ£€æŸ¥è¾“å…¥æ•°æ®:")
    check_tensor_health(images, "images")
    check_tensor_health(points, "points")
    check_tensor_health(adjacency, "adjacency")
    print(f"node_masks shape: {node_masks.shape}, active nodes per batch: {node_masks.sum(dim=1)}")
    
    # é€æ­¥å‰å‘ä¼ æ’­
    print("\nğŸ”„ å¼€å§‹é€æ­¥å‰å‘ä¼ æ’­...")
    
    model.train()
    
    try:
        # 1. CNNç¼–ç å™¨
        print("1. CNNç¼–ç å™¨...")
        image_features = model.cnn_encoder(images)
        check_tensor_health(image_features, "image_features")
        
        # 2. èŠ‚ç‚¹å›å½’å™¨
        print("2. èŠ‚ç‚¹å›å½’å™¨...")
        predicted_coords, node_counts = model.node_regressor(image_features)
        check_tensor_health(predicted_coords, "predicted_coords")
        check_tensor_health(node_counts, "node_counts")
        
        # 3. å›¾æ„å»ºå™¨
        print("3. å›¾æ„å»ºå™¨...")
        edge_index, edge_weight = model.graph_builder.build_knn_graph_vectorized(
            predicted_coords, node_masks)
        print(f"edge_index shape: {edge_index.shape}")
        if edge_index.numel() > 0:
            check_tensor_health(edge_weight, "edge_weight")
        else:
            print("âš ï¸  æ²¡æœ‰ç”Ÿæˆè¾¹")
        
        # 4. GNNå¤„ç†å™¨
        print("4. GNNå¤„ç†å™¨...")
        node_features = model.gnn_processor(predicted_coords, edge_index, edge_weight, node_masks)
        check_tensor_health(node_features, "node_features")
        
        # 5. è¾¹é¢„æµ‹å™¨
        print("5. è¾¹é¢„æµ‹å™¨...")
        adjacency_matrix, adjacency_logits = model.edge_predictor(node_features, node_masks)
        check_tensor_health(adjacency_matrix, "adjacency_matrix")
        check_tensor_health(adjacency_logits, "adjacency_logits")
        
        print("âœ… å‰å‘ä¼ æ’­å®Œæˆ")
        
        # å‡†å¤‡ç›®æ ‡æ•°æ®
        targets = {
            'points': points,
            'adjacency': adjacency,
            'node_masks': node_masks
        }
        
        predictions = {
            'predicted_coords': predicted_coords,
            'node_counts': node_counts,
            'adjacency_matrix': adjacency_matrix,
            'adjacency_logits': adjacency_logits,
            'node_features': node_features,
            'image_features': image_features,
            'edge_index': edge_index,
            'edge_weight': edge_weight
        }
        
        # 6. æŸå¤±è®¡ç®—
        print("6. æŸå¤±è®¡ç®—...")
        loss_dict = criterion(predictions, targets)
        
        print("æŸå¤±è¯¦æƒ…:")
        for key, value in loss_dict.items():
            print(f"  {key}: {value.item():.6f}")
            if torch.isnan(value):
                print(f"  âŒ {key} is NaN!")
            elif torch.isinf(value):
                print(f"  âŒ {key} is Inf!")
        
        # 7. åå‘ä¼ æ’­æµ‹è¯•
        print("7. åå‘ä¼ æ’­æµ‹è¯•...")
        optimizer = torch.optim.Adam(model.parameters(), lr=0.001)
        optimizer.zero_grad()
        
        loss_dict['total_loss'].backward()
        
        # æ£€æŸ¥æ¢¯åº¦
        has_nan_grad, has_inf_grad = check_model_gradients(model)
        
        if not has_nan_grad and not has_inf_grad:
            print("âœ… æ¢¯åº¦å¥åº·")
            optimizer.step()
            print("âœ… ä¼˜åŒ–å™¨æ­¥éª¤å®Œæˆ")
        else:
            print("âŒ æ¢¯åº¦åŒ…å«NaNæˆ–Inf")
        
    except Exception as e:
        print(f"âŒ é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
        
    print("\nğŸ¯ è°ƒè¯•å®Œæˆ")

if __name__ == "__main__":
    debug_model_step()