#!/usr/bin/env python3
"""
ä¿®å¤ evaluation_metrics.py ç¼ºå¤±çš„ compute_batch_metrics æ–¹æ³•
"""

import os
import sys

def fix_evaluation_metrics():
    """æ·»åŠ ç¼ºå¤±çš„ compute_batch_metrics æ–¹æ³•"""
    
    # æ‰¾åˆ° evaluation_metrics.py æ–‡ä»¶
    eval_file = "utils/evaluation_metrics.py"
    
    if not os.path.exists(eval_file):
        print(f"âŒ æ‰¾ä¸åˆ°æ–‡ä»¶: {eval_file}")
        return False
    
    # è¯»å–ç°æœ‰æ–‡ä»¶
    with open(eval_file, 'r', encoding='utf-8') as f:
        content = f.read()
    
    # æ£€æŸ¥æ˜¯å¦å·²ç»æœ‰è¯¥æ–¹æ³•
    if 'def compute_batch_metrics(' in content:
        print("âœ… compute_batch_metrics æ–¹æ³•å·²å­˜åœ¨")
        return True
    
    # æ‰¾åˆ°æ’å…¥ç‚¹ï¼ˆåœ¨ evaluate_batch æ–¹æ³•ä¹‹åï¼‰
    method_to_add = '''
    def compute_batch_metrics(self, pred_adj, true_adj, masks, clustering_method='spectral'):
        """
        è®¡ç®—æ‰¹æ¬¡æŒ‡æ ‡ï¼Œä¸è®­ç»ƒè„šæœ¬æ¥å£å…¼å®¹
        
        Args:
            pred_adj: é¢„æµ‹çš„é‚»æ¥çŸ©é˜µ [batch_size, max_nodes, max_nodes] (numpy array)
            true_adj: çœŸå®çš„é‚»æ¥çŸ©é˜µ [batch_size, max_nodes, max_nodes] (numpy array)
            masks: èŠ‚ç‚¹æ©ç  [batch_size, max_nodes] (numpy array)
            
        Returns:
            Dictionary containing lists of metrics for each sample
        """
        import torch
        import numpy as np
        
        batch_size = pred_adj.shape[0]
        
        # åˆå§‹åŒ–æŒ‡æ ‡åˆ—è¡¨
        ari_scores = []
        nmi_scores = []
        modularity_scores = []
        inference_times = []
        
        for b in range(batch_size):
            node_mask = torch.from_numpy(masks[b]).bool()
            valid_nodes = node_mask.sum().item()
            
            if valid_nodes <= 1:
                # è·³è¿‡æ— æ•ˆæ ·æœ¬
                ari_scores.append(0.0)
                nmi_scores.append(0.0)
                modularity_scores.append(0.0)
                inference_times.append(0.0)
                continue
                
            # è½¬æ¢ä¸ºå¼ é‡
            adj_true = torch.from_numpy(true_adj[b]).float()
            adj_pred = torch.from_numpy(pred_adj[b]).float()
            
            # æå–ç¤¾åŒºæ ‡ç­¾
            true_labels = self.create_ground_truth_labels(adj_true, node_mask)
            pred_labels = self.extract_communities_from_adjacency(
                adj_pred, node_mask, method=clustering_method
            )
            
            # è®¡ç®—æŒ‡æ ‡
            ari = self.calculate_ari(true_labels, pred_labels)
            nmi = self.calculate_nmi(true_labels, pred_labels)
            modularity = self.calculate_modularity(adj_pred, node_mask, pred_labels)
            
            ari_scores.append(ari)
            nmi_scores.append(nmi)
            modularity_scores.append(modularity)
            inference_times.append(1.0)  # å ä½ç¬¦ï¼Œå®é™…æ¨ç†æ—¶é—´åœ¨å¤–éƒ¨è®¡ç®—
        
        # è¿”å›åˆ—è¡¨å½¢å¼çš„æŒ‡æ ‡ï¼ˆä¸è®­ç»ƒè„šæœ¬æœŸæœ›çš„æ ¼å¼åŒ¹é…ï¼‰
        return {
            'ARI': ari_scores,
            'NMI': nmi_scores,
            'Modularity': modularity_scores,
            'Inference_Time_ms': inference_times
        }
'''
    
    # åœ¨æœ€åä¸€ä¸ªæ–¹æ³•ä¹‹åæ’å…¥æ–°æ–¹æ³•
    # æ‰¾åˆ° "def test_evaluation_metrics():" ä¹‹å‰æ’å…¥
    if 'def test_evaluation_metrics():' in content:
        insert_point = content.find('def test_evaluation_metrics():')
        new_content = content[:insert_point] + method_to_add + "\n\n" + content[insert_point:]
    else:
        # å¦‚æœæ²¡æœ‰æ‰¾åˆ°æµ‹è¯•å‡½æ•°ï¼Œåœ¨æ–‡ä»¶æœ€åæ’å…¥
        new_content = content + method_to_add
    
    # å†™å›æ–‡ä»¶
    with open(eval_file, 'w', encoding='utf-8') as f:
        f.write(new_content)
    
    print("âœ… æˆåŠŸæ·»åŠ  compute_batch_metrics æ–¹æ³•åˆ° evaluation_metrics.py")
    return True

if __name__ == "__main__":
    print("ğŸ”§ ä¿®å¤ evaluation_metrics.py...")
    success = fix_evaluation_metrics()
    
    if success:
        print("âœ… ä¿®å¤å®Œæˆï¼ç°åœ¨å¯ä»¥é‡æ–°è¿è¡Œè®­ç»ƒè„šæœ¬")
        print("ğŸ“ è¿è¡Œ: python train_model_b_only.py")
    else:
        print("âŒ ä¿®å¤å¤±è´¥ï¼Œè¯·æ‰‹åŠ¨æ£€æŸ¥æ–‡ä»¶")